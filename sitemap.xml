<search>
    <entry>
        <title>Learning High Frequency Trading in Market Microstructure Study</title>
        <url>https://dennislblog.github.io/2020/07/20_07_20-market-hft/</url>
        <categories>
          <category>Review</category><category>Knowledge</category>
        </categories>
        <tags>
          <tag>book</tag><tag>hft</tag>
        </tags>
        <content type="html"> some notes from two high frequency textbooks.
Market Microstructure in Practice In 1985, Kyle proposed a simple toy model explaining how a market maker, an informed and many homogenous uninformed traders can coexist and lead to market impact. To protect itself from adverse selection, the market maker proposes a price adjustment rule that is linearly proportioned to the observed net order flow with coefficient (also called Kyle&#39;s Lambda) $\lambda = (2\sigma_u)^{-1}\sqrt{\Sigma_0}$. The more the potential informational price move (i.e., large $\Sigma_0$, the larger the price impact and the more the non-informative order flow (i.e., large $\sigma_u$), the more difficult for the market maker to discern price information, hence the less market price would be affected.&amp;mdash; Appendix A.4 (Kyle&amp;#39;s model) High-Frequency Trading Transaction costs present a considerable hurdle for high-frequency trading systems. Among all costs, however, market impact accounts for the most significant proportion of costs. Understanding and measuring the current cost structure is imperative to designing profitable systems.&amp;mdash; Chapter Ch5 Summary A mutual fund manager with superior stock selection ability is more likely to benefit from trading in stocks affected by information-events. Funds trading high-PIN stocks exhibit superior performance on average, and this effect is not due to higher returns earned by high-PIN stocks on average.&amp;mdash; Chapter Ch5 Summary Easley and O&#39;Hara Despite large volumes traded on exchanges, many listed stocks trade infrequently. Most trading volumes are concentrated on some popular stocks. One characteristic of low frequently-traded stocks is their large bid-ask spreads. For stocks in the lower volume deciles on the NYSE, spreads as a percentage of stock price can be 50% larger than those of frequently traded stocks.&amp;mdash; Easley and O&amp;#39;Hara, 1996, p1 They have empirically shown that frequently-traded stocks have lower informational risk as compared to infrequently-traded ones. The higher arrival rates of non-informative order flow offsets higher arrival rates of informed traders and information events.
The Model It differs from Kyle and Glosten in that it models the arrival rates of traders to the market in a continuous fashion $t \in [0, T]$. The competitive price is always set as the expected value conditioned on market information. In active markets, prices could adjust to new information in minutes and new information events could occur quite frequently. In inactive markets, there may not even be a single trade on some days. In this paper, they assume the information event occurs only between trading days.
Let $\langle V_i \rangle_{i=1:l}$ be the asset&#39;s price at the end of trading days $i=1, \cdots, l$. Prior to the beginning of any trading day, nature decides whether an information event (i.e., news) occurs (w.p. $\alpha$). The value on day $i$ is $\overline{V}$ conditioned on good news (w.p. $1-\delta$) and $\underline{V}$ conditioned on bad news (w.p. $\delta$). If no information event has occurred, the expected value remains at its unconditional level $V^* = \delta \underline{V} &#43; (1-\delta)\overline{V}$. In the Glosten and Milgrom, the informational event always exists (i.e., $\alpha = 1$). The informed traders observe the signal and take the price as given (i.e., competitive players).
The common rule is that with the underlying tree structures, more buys are expected on days with good events and more sells on days with bad events1. And fewer trades happen on no-event days because of the absence of informed traders.
Reference [1] Laruelle, S., &amp;amp; Lehalle, C. A. (2018). Market microstructure in practice. World Scientific.
[2] Aldridge, I. (2013). High-frequency trading: a practical guide to algorithmic strategies and trading systems (Vol. 604). John Wiley &amp;amp; Sons.
[3] Easley, D., &amp;amp; O&amp;rsquo;hara, M. (1992). Time and the process of security price adjustment. The Journal of finance, 47(2), 577-605.
  Note that, unlike in a Kyle (1985) framework, trades in our model are not aggregated, so it is the composition and total number of trades that determines beliefs and, thus, prices. &amp;#x21a9;&amp;#xfe0e;
  </content>
    </entry><entry>
        <title>Review of Competing Market Makers</title>
        <url>https://dennislblog.github.io/2020/06/20_06_30-imperfect-competition/</url>
        <categories>
          <category>Thesis</category>
        </categories>
        <tags>
          <tag>thesis</tag><tag>review</tag><tag>finance</tag>
        </tags>
        <content type="html"> To better understand market player&amp;rsquo;s equilibrium responses in a perfect competitive marketplace, we take our look at how the imperfect competition among finite many market makers drives the dynamics of price discovery. In this post, I will review two papers: one that investigates price competition among $M$ market makers (Bondarenko, 2001) and another where $M$ liquidity providers submit their demand price schedule (i.e., quantities) based on a common clearing price (Nishide, 2006). Through reviewing these works, I hope to gain insight on how imperfect competition among market makers (or liquidity providers) affects the price formation and price discovery during the trading periods.
.notice{padding:18px;line-height:24px;border-radius:4px;color:#444;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:0.125em;position:relative}why study on imperfect competition is substantially harder than perfect competition?Imperfect competition is more realistic in that it allows differentiation between the same product being sold. For example, the same shoe can be sold with different price because of different customer ratings.
 In the perfectly competitive world, all market makers set the same price equal to the expected value conditioned on market information, i.e., $p = \mathbb{E}[v | \mathcal{F}]$ In the imperfectly competitive world, market makers have the freedom to quote however much they want for a share to trade and influence the market price altogether. To maximize individual profit, each market maker must know how the informed and uninformed trade. Will the equilibrium price set by each market maker be the same and equal to the competitive price in above case? Let&#39;s try to answer that.   Bondarenko&#39;s Paper Why cannot an equilibrium exist for two competing market makers?Suppose at the $n$-th auction, $\mathcal{M}_{2:M}$ all set its price schedule with $\lambda_{\cdot n} = l$ but the first market maker who deviates the equilibrium chooses $\lambda_{1n} = l&amp;rsquo; &amp;gt; l$. Then this deviation will have four effects:
  The slope of the effective schedule (by all $\mathcal{M}_{1:M}$) is $\lambda_n := \left(\sum_{i=1}^m \lambda_{in}^{-1}\right)^{-1}$, will become higher.
  The aggregate order by uninformed traders routed to the first market maker $\Delta u_{1n} = \frac{\lambda_n}{\lambda_{1n}}\Delta u_n$ decreases
  Both the informed trader&#39;s $\mathcal{M}_1$ specific demand ($\beta_{1n}= \frac{\lambda_n}{\lambda_{1n}}\beta_n$) and aggregate demand ($\beta_n = \frac{m-2}{m-1}\lambda_n \rho_n^2$ where $\rho = \frac{\sigma_u}{\sigma_v}$) decrease
   Nishide&#39;s Paper Contr
 Introducing Spread to Kyle Strategy Space
  Two market makers ($m \in {1,2}$) simultaneously announce ask and bid price schedule? (but price is final after observing the aggregate net order flow)
$$\begin{align*} P_m^&#43; &amp;amp;= \alpha &#43; \beta_m y_m &#43; \Delta \cr P_m^- &amp;amp;= \alpha &#43; \beta_m y_m - \Delta \end{align*}$$
where total net order $y_m = x_m &#43; \sum_n z_{nm}$ for $n$ noise traders. Both $\alpha, \Delta \in \mathbb{R}_&#43;$ are exogenous.
  The informed knows true value $v \sim \mathbf{N}(\alpha, \sigma_v^2)$ and submits an order $x_m \in \mathbb{R}$ to each of the two market makers.
  The noise trader $n \in {1, \cdots, N}$ observes $u_n \sim \mathbf{N}(0, \sigma_u^2/N)$ and submits $z_{nm}$ to each market maker. $z_{n1} &#43; z_{n2} = u_n$ and $|z_{n1}|, |z_{n2}| \leq |u_n|$
  Equilibrium AnalysisThe Payoff
  Market Maker ($m \in {1,2}$)
$$\begin{align*} \pi_m(\beta_m) &amp;amp;= (P_m^&#43; - v)\left(x_m^&#43; &#43; \sum_n z_{nm}^&#43;\right) &#43; (P_m^- - v)\left(x_m^- &#43; \sum_n z_{nm}^-\right) \cr &amp;amp;= (P_m - v)\left(x_m &#43; \sum_n z_{nm}\right) &#43; \Delta \left(|x_m| &#43; \sum_n |z_{nm}|\right) \end{align*}$$
  Informed Trader
$$\begin{align*} \pi(x_1, x_2) &amp;amp;= \sum_{m=1,2} [(v-P_m^&#43;)x_m^&#43; &#43; (v-P_m^-)x_m^-] \cr &amp;amp;= \sum_{m=1,2} [(v-P_m)x_m - \Delta |x_m|] \end{align*}$$
  Uninformed Traders
$$\begin{align*} \pi(z_{n1}, z_{n2}) &amp;amp;= \sum_{m=1,2} [(v-P_m^&#43;)z_{nm}^&#43; &#43; (v-P_m^-)z_{nm}^-] \cr &amp;amp;= \sum_{m=1,2} [(v-P_m)z_{nm} - \Delta |z_{nm}|] \end{align*}$$
How to derive the $i$-th uninformed trader&#39;s optimal response? Well, let&#39;s first assume everybody else play by the equilibrium, then (only extract what&#39;s relevant to the $i$-th row)
$$\begin{align*} \mathbb{E}[\pi_i | \beta^*, x^*, z^*_{-i}, u_n=u] &amp;amp;= \mathbb{E}[v - (\alpha - \beta^*(x^*&#43;u-z^*_{-i} &#43; z_i)) - \Delta |u-z^*_{-i} &#43; z_i|] \cr &amp;amp;= -\beta^*_1z^2_{i1} - \Delta |z_{i1}| - -\beta^*_2(u - z_{i1})^2 - \Delta |u - z_{i1}| \end{align*}$$
take the derivative w.r.t. $z_{im}$, and solve a system of two ODE, we have $z_{im}^* = \frac{\beta_{-m}}{\beta_{-m} &#43; \beta_{m}}u$
  conclusion
 when competition is introduced, the price sensitivity $\lambda$ is no longer just interpreted as a measure of the spread. this is still a static analysis of Kyle&#39;s extended model with spread. A dynamic model is called for. in my thesis, I have not considered imperfect game and how equilibrium is reached. Instead, my scope of research is still on perfect competition setting. However it is interesting to introduce spread to the original Kyle&#39;s work.  Reference [1] Bondarenko, O. (2001). Competing market makers, liquidity provision, and bid‚Äìask spreads. Journal of Financial Markets, 4(3), 269-308.
[2] Nishide, K. (2006). Insider trading with imperfectly competitive market makers.
[3] Dennert, J. (1993). Price competition between market makers The Review of Economic Studies, 60(3), 735-751.
[4] Osterrieder, J. (2005). A dynamic market microstructure model with market orders and random order book depth Available at SSRN 2984315.
[5] Salomonsson, M. (2009). Introducing a spread into the Kyle model (No. 713). SSE/EFI Working Paper Series in Economics and Finance.
[6] Calcagno, R., &amp;amp; Lovo, S. (2006). Bid-ask price competition with asymmetric information between market-makers The Review of Economic Studies, 73(2), 329-355.
</content>
    </entry><entry>
        <title>Review of Market Microstructure Studies</title>
        <url>https://dennislblog.github.io/2020/06/20_06_29-model-review/</url>
        <categories>
          <category>Thesis</category>
        </categories>
        <tags>
          <tag>thesis</tag><tag>review</tag><tag>finance</tag>
        </tags>
        <content type="html"> Although market microstructure models have been proposed for over thirty years, only a few studies on how market makers and informed traders interact to form a competitive price (Cho, 2004). In this blog, I will review several market microstructure models with detailed analysis.
Motivation I have read the paper of Kyle and Glosten &amp;amp; Milgrom for nearly 20&#43; times but never got the chance to sit down and thoroughly challenge myself with all technical aspects of these papers. In both models, a precise understanding of informed activities is vital in the effective price discovery and successful market making. The main difference between two models is how information risk is defined and understood by the market maker.
In Glosten &amp;amp; Milgrom&#39;s model, there is uncertainty about whether the upcoming trading is associated with an informed trader and this risk remains unchanged regardless of market signals (i.e., sequence of past auctions). The so-called market signals can be quite misleading sometimes. For example, people keep buying stocks at high prices with the belief that they will sell them at a higher price. However the stock may not worth the price they pay.
In Kyle&#39;s model, the informed trader involves in each trading but her activity is disguised by uninformed trader&#39;s behaviors. Because the only person who is informed of true asset value can participate in every tradings, she can deliberately trade less or more to protect the market maker from discovering the true price. In reality, traders may split a large order into small child orders over a longer period to avoid adverse price impact. The risk can be quantified as the market maker&#39;s uncertainty about true value, for example, the confidence interval around the point estimation about the true value.
Notes on the Kyle&#39;s Order-Driven Batch Trading Model The main interest of this paper is to figure out how do I optimally trade privately-known information for profit as the only informed player in the game. The protocol of trading governing the market corresponds to that of a call auction.
.notice{padding:18px;line-height:24px;border-radius:4px;color:#444;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:0.125em;position:relative}Call Auction and Its Definition in This PaperA call auction puts many small orders1 together in one batch and clear as many shares as possible at one price (while minimizes residual imbalances). Rather than continuous double auctions (e.g., the continuous version of Glosten-Milgrom model) that match multiple orders throughout the day, a call auction takes place in the beginning or the end of a trading day (i.e., opening and closing call auctions) to disseminate buy/sell order imbalances (see source).
The trading mechanism in Kyle&#39; model is a simplified version of a call auction in that (1) traders submit market orders only and (2) all orders are cleared with a single price and no residual imbalances remains.
  although all orders are limit orders, they are executed at a common price rather than the exact limit price in continuous trading. For example, a buy order listed at $\$25$ may be executed at $\$24$ in this call auction. &amp;#x21a9;&amp;#xfe0e;
   Notations
List of Symbol for Kyle Model   Symbol Definition     $N$ Number of trade rounds taking places, $0 = t_0 &amp;lt; t_1 \cdots &amp;lt; t_N = 1$   $V$ True asset value $V \sim \mathbb{N}(p_0, \Sigma_0)$ secretly known to the informed at $t_0$ and publicly announced at $t_N$   $u_n$ The aggregated position of all uninformed traders after $n$-th round of game. It is assumed to be a random walk process with zero mean and $\sigma_u^2$ variance   $\Delta u_n$ The quantity to trade at $n$-th round by all uninformed traders, i.e., $\Delta u_n = u_n - u_{n-1}$   $x_n$ The aggregated position of the informed trader after $n$-th round of game. It is a function of price and true value, i.e., $x_n = f(p_{1:n-1}; V)$   $\Delta x_n$ The quantity to trade at $n$-th round by the informed trader, $\Delta x_n = x_n - x_{n-1}$   $p_n$ The market clear price to liquidate all remaining $\Delta x_n &#43; \Delta u_n$ market orders at $n$-th round of game. The price is set on the basis of both current order flow as well as historical records, i.e., $p_n = g((\Delta x_i &#43; \Delta u_i)_{i=1:n})$   $\Delta p_n$ The market clear price change at $n$-th round, $\Delta x_n = x_n - x_{n-1}$   $I_n$ The public information at post-trade point $n$ including market clearing price and net order quantities, i.e., $I_n = \{p_n, (x_n&#43;u_n)\}$ and $I_0 = p_0$   $\pi_n$ The profit of the informed trader on position acquired at the $n, \cdots N$ rounds of auctions, i.e., $\pi_n = (V-p_n)\Delta x_n &#43; \pi_{n&#43;1}$ and $\pi_{N&#43;1}=0$    General Time Flow Two main differences to Glosten and Milgrom&#39;s model are:
 only one (instead of infinitely many) informed trader participates in the trading and she is allowed to trade as much as possible to exploit her informational advantages market orders are submitted first and then executed at a common price set by the market maker  
Single-period Analysis The intuition behind market maker&#39;s pricing rule is that abnormally large order size arises from more aggressive insider activities1. Therefore, the market maker would set $p$ higher (lower) if $u&#43;x$ is positively (negatively) high.
An equilibrium is reached when the market maker&#39;s pricing rule and the informed trader&#39;s trading strategy are fixed such that (1) zero expected profits are made by the market maker; (2) maximized profits are made by the informed trader.
Assume a competitive market is in equilibrium, the market maker engaging in this unending price undercutting war must earn a zero expected profit conditioned on order flow information: $$\begin{align*} p(y) &amp;amp;= \mathbb{E}[V | y] &amp;amp;&amp;amp; \text{let } y = x &#43; u \cr &amp;amp;= \mathbb{E}[V] &#43; \frac{\mathrm{Cov}(V, y)}{\mathrm{Var}(y)}(y - \mathbb{E}[y]) &amp;amp;&amp;amp; \text{from projection theorem} \end{align*}$$
Now assume the pricing rule is a linear function of the net order flow $y = x &#43; u$, i.e., $p(y) = \mu &#43; \lambda y$. The informed trader chooses $x$ such that her expected profit is maximized: $$\begin{align*} x^* &amp;amp;= \arg\max_x (V-\mu-\lambda x)\cdot x &amp;amp;&amp;amp; p(x&#43;u) = \mu &#43; \lambda (x &#43;u) \cr &amp;amp;= \frac{V-\mu}{2\lambda} \end{align*}$$
Knowing the market maker uses a linear pricing rule, the informed would respond accordingly by the above equation. Her optimal response is also linear in $V$ with a non-negative expected profit (i.e., $(4\lambda)^{-1}(V-\mu)^2$).
Now we can go back to market maker&#39;s pricing function with the knowledge of the informed&#39;s optimal strategy $x = (2\lambda)^{-1}(V-\mu)$. $$\begin{align*} \mathbb{E}[V] &amp;amp;= p_0 &amp;amp;&amp;amp; \text{since } V\sim \mathbb{N}(p_0, \Sigma_0) \cr \mathrm{Cov}[V, x&#43;u] &amp;amp;= \frac{\Sigma_0}{2\lambda} &amp;amp;&amp;amp; \text{both u and V are independent random variables} \cr \mathrm{Var}[x&#43;u] &amp;amp;= \sigma_u^2 &#43; \frac{\Sigma_0}{4\lambda^2} &amp;amp;&amp;amp; u, x \text{ are independent}\cr \mathbb{E}[x&#43;u] &amp;amp;= (2\lambda)^{-1}(p_0 - \mu) &amp;amp;&amp;amp; \mathbb{E}[u]=0 \end{align*}$$
We can thus solve for the optimal pricing rule $p(y) = \lambda y &#43; \mu$ and the informed&#39;s best strategy
$$\begin{align*} p(x&#43;u) &amp;amp;= p_0 &#43; \lambda(x&#43;u) \cr x(V) &amp;amp;= 2^{-1}\lambda^{-1}(V- p_0) \end{align*}$$
where $\lambda = (2\sigma_u)^{-1}\sqrt{\Sigma_0}$ (also called Kyle&#39;s lambda) captures the information risk sensed by the market maker. It relates itself to (1) the endogenous risk of asset value $\Sigma_0$ and (2) the volatility of noise trading $\sigma_u$. From the informed trader&#39;s perspective, she exploits the information advantages (i.e., $V - p_0$) more aggressively when $\lambda$ is lower. That is when the presence of noise trading provides an effective camouflage for informed tradings2 ($\sigma_u \nearrow$) and the asset value uncertainty is low ($\Sigma_0 \searrow$). We would naturally reason the informed trader would trade more aggressively when the value uncertainty is high instead of low. However it shows the opposite here because the market maker is more suspicious of demand abnormality arising from informed tradings when she is quite uncertain about true asset value. Therefore, the informed trader responds in a restrained manner to maximize her profits.
From the perspective of the market maker, information risk is perceived to be higher when asset value is highly uncertain ($\Sigma_0 \nearrow$) and the volatility of liquidity trading activities is low ($\sigma_u \searrow$). It is essentially a signaling game with noise. The market maker sets the price after observing the signal plus a noise controlled by $\sigma_u$. When signal is strong (low $\sigma_u$), a large size of market orders are likely to arise from high involvement of the informed&#39;s activity.
 Multi-period Analysis Let the public information available at post-trade point $t$ be $I_t = \{p_t, (x_t&#43;u_t)\}$ where $I_0 = p_0$. We can calculate post-trade residual value uncertainty (i.e., $\Sigma_t$) conditioned on trading signals and information:
$$\begin{align*} \Sigma_t &amp;amp;= \mathrm{Var}[V | I_{0:t}] = \mathbb{E}\left[\mathrm{Var}[V | I_{0:t}]|I_{0:t-1}\right] &amp;amp;&amp;amp; \text{since information about variance is already included}\cr &amp;amp;= \mathrm{Var}[V|I_{0:t-1}] - \mathrm{Var}\left[\mathbb{E}[V|I_{0:t}]|I_{0:t-1}\right] &amp;amp;&amp;amp; \text{by the law of total conditional variance } \cr &amp;amp;= \Sigma_{t-1} - \mathrm{Var}[p_t | I_{0:t-1}] &amp;amp;&amp;amp; \text{assume pricing function is linear on the current signal only} \cr &amp;amp;= \Sigma_{t-1} - \lambda^2((2\lambda)^{-2}\Sigma_{t-1} &#43; \sigma_u^2) &amp;amp;&amp;amp; \text{since } p_t = p_{t-1} &#43; \lambda(x_t&#43;u_t) \text{ and } x_t = (2\lambda)^{-1}(V-p_{t-1}) \cr &amp;amp;= 2^{-1}\Sigma_{t-1} &amp;amp;&amp;amp; \text{assume both strategy stay the same} \end{align*}$$
Thus asset value uncertainty is expected to reduce in half if the informed has no incentive to hide information and pursue a myopic trading strategy (i.e., greedily maximize period profits). The informed trader exploits her private information about $V$ to the fullest in each trading period.
However, a far-sight agent would choose to maximize both immediate and long-run profits by taking into account price impact in both the current and future auctions.
Assumptions Made to Reach EquilibriumAssume the market maker&#39;s pricing rule and the informed&#39;s trading (or position) strategy are both linear at each trading period, i.e., $x_n = f_n(p_{1:n}, V), p_n = g_n((x_k&#43;u_k)_{k=1:n})$ where both $f_n$ and $g_n$ are linear functions.
More specifically, a recursive linear equilibrium (replace $x_n$ with $\Delta x_n$ and introduce markov property) wants to be reached such that $$\begin{align*} p_n &amp;amp;= p_{n-1} &#43; \lambda_n(\Delta x_n &#43; \Delta u_n) \cr x_n &amp;amp;= x_{n-1} &#43; \beta_n(V - p_{n-1})\Delta t_n \cr \Delta t_n &amp;amp;= N^{-1} \end{align*}$$
Now define $\mathcal{F}, \mathcal{G}$ to be vectors of strategies
$$\begin{align*} \mathcal{F} &amp;amp;= \langle f_1, \cdots, f_N \rangle &amp;amp;&amp;amp; x_n = x_{n-1} &#43; f_n(p_{n-1}) \cr \mathcal{G} &amp;amp;= \langle g_1, \cdots, g_N \rangle &amp;amp;&amp;amp; p_n = p_{n-1} &#43; g_n(\Delta x_n &#43; \Delta u_n) \end{align*}$$
The linear recursive equilibrium is defined as a pair $\langle \mathcal{F}, \mathcal{G} \rangle$ such that the following two conditions hold:
  Profit Maximization: the informed&#39;s strategic profile is optimal regardless of when she participated in the game: $$\mathbb{E}[\pi_n(\mathcal{F}, \mathcal{G}) | p_{1:n-1}, V] \geq \mathbb{E}[\pi_n(\mathcal{F}&#39;, \mathcal{G}) | p_{1:n-1}, V] \qquad \forall n = 1, \cdots N$$
  Market Efficiency: the market maker always sets a competitive price to earn zero expected profit: $$p_n = \mathbb{E}[V | (x_k&#43;u_k)_{k=1:n}] \qquad \forall n = 1, \cdots N$$
  Similarly to how single-period problem is solved, optimal trading strategy is obtained via maximizing future aggregated profits $\pi_n$ and competitive pricing rule follows from market efficiency hypothesis via the use of projection theorem:
  The informed&#39;s profits are of the quadratic form $\mathbb{E}[\pi_{n&#43;1}(\mathcal{F}, \mathcal{G}) | p_{1:n}, V] = \alpha_n(V-p_n)^2 &#43; \delta_n$ where $$\begin{align*} \alpha_n &amp;amp;= (4\lambda_{n&#43;1}(1-\alpha_{n&#43;1}\lambda_{n&#43;1}))^{-1} \cr \delta_n &amp;amp;= \delta_{n&#43;1} &#43; \alpha_{n&#43;1}\lambda^2_{n&#43;1}\sigma_u^2\Delta t_{n&#43;1} \cr \Delta x_n &amp;amp;= (2\lambda_n(1-\alpha_n\lambda_n))^{-1}(1-2\alpha_n\lambda_n)(V - p_{n-1}) \end{align*}$$
  The market maker always sets a competitive price following the law of market efficiency. Based on linear recursive form $\Delta p_n = \lambda_n(\Delta x_n &#43; \Delta u_n)$ and value uncertainty $\Sigma_n = \mathrm{Var}[V | I_{0:t}]$ where $$\begin{align*} \Sigma_n &amp;amp;= (1-\beta_n\lambda_n\Delta t_n)^{-1}\Sigma_{n&#43;1} \cr \lambda_n &amp;amp;= \sigma_u^{-2}\Sigma_n\beta_n \end{align*}$$
The market maker&#39;s risk sensitivity can be rewritten as $\lambda_n = (\sigma_u\sqrt{\Delta t_n})^{-1}\sqrt{\Sigma_{n-1}-\Sigma_n}\sqrt{\frac{\Sigma_n}{\Sigma_{n-1}}}$, which achieves its maximum when $\Sigma_n = 0.5\Sigma_{n-1}$ (i.e., with the newly received order flow information $\Delta x_n &#43; \Delta u_n$, the value uncertainty is reduced as shown in the single period analysis). From the informed&#39;s perspective, if she deliberately hides information and splits large orders, the market maker might be less sensitive in response. From the market maker&#39;s perspective, a precise estimation of value uncertainty is vital in the effective price discovery.
  Now we can start with a guessing $\Sigma_N$ (i.e., the residual uncertainty after the last trading and right before the true value is publicly announced) and use backward iteration to check the correct initial value $\Sigma_0$. Since no trade happens after $t_N$, the informed naturally has no profits $\mathbb{E}[\pi_{N&#43;1}(\cdot) | p_{1:n}, V] = \alpha_N(V-p_N)^2 &#43; \delta_N = 0 \Rightarrow \alpha_N, \delta_N = 0$. With $\alpha_N = 0$, we can use the above equations to derive $$\begin{align*} \lambda_N &amp;amp;= (\sigma_u\sqrt{2\Delta t_N})^{-1}\sqrt{\Sigma_N} \cr \beta_N &amp;amp;= (2\lambda_N\Delta t_N)^{-1} \cr \alpha_{N-1} &amp;amp;= (4\lambda_N(1-\alpha_N\lambda_N))^{-1} \cr \delta_{N-1} &amp;amp;= \delta_N &#43; \alpha_N\lambda^2_N\sigma_u^2\Delta t_N \cr \end{align*}$$
  Noted that $\lambda_1 = (\sigma_u\sqrt{2})^{-1}\sqrt{\Sigma_1}$ and $\beta_1 = (2\lambda_1)^{-1}$ in the single period game. We have a consistent result if we set $N=1$.
Plotly.d3.json(&#34;./kyle_price.json&#34;, function(err, fig) {Plotly.plot(&#39;.\/kyle_price.json&#39;, fig.data, fig.layout, {responsive: true});}); Glosten and Milgrom&#39;s Sequential Trading Model A randomly selected traders arrive at the market and participate in the market once.
Notations
List of Symbol for Glosten &amp; Milgrom Model   Symbol Definition     $V$ True asset value announced at $T$, $V \in \{ \underline{V}, \overline{V}\}$   $s_n$ Market signal received at $n$-th trading, $s_n \in \{s^B, s^S\} \forall n$ (i.e., either a market buy or a market sell order)   $N_n$ The collective number of market buy or market sell signals, $N^B_n = |s^B_{1:n}|, N^S_n = |s^S_{1:n}|$   $\theta$ Type of traders, $\theta \in \{\theta^U, \theta^I \}$ (i.e., either uninformed or informed type)   $p_n$ Quoted ask and bid price for 1 share of asset, $p_n \in \{p_n^A, p_n^B\}$ (i.e., ask and bid price)   $\mu$ The population of informed traders, $0\% \leq \mu \leq 100\%$   $\delta_n$ Market maker&#39;s belief about realization value being $\underline{V}$ after $n$-th trading    Two main differences to Kyle&#39;s model are:
 There are many homogeneous informed traders and each selected to arrive at the market cannot reenter the game. Therefore, she will sell all her information to achieve highest possible profits. Two prices (bid and ask) are determined by the market maker and one randomly selected trader (informed or uninformed) submits either a market buy order or a market sell order.  General Time Flow 
Single-period Analysis From conditional expectation that $$\mathbb{E}(V | s^B) = \mathbb{E}(V |\theta^U,s^B)\Pr(\theta^U|s^B) &#43; \mathbb{E}(V |\theta^U,s^B)\Pr(\theta^U|s^B)$$
Since ask price is set to be the expected value conditioned on seeing a potential market buy, we can replace $p^A = p^A[\Pr(\theta^U|s^B) &#43; \Pr(\theta^I|s^B)] = \mathbb{E}(V | s^B)$. Rearrange the terms and we have
$$\left[p^A - \mathbb{E}(V |\theta^U,s^B)\right]\Pr(\theta^U|s^B) = -\left[p^A - \mathbb{E}(V |\theta^I,s^B)\right]\Pr(\theta^I|s^B)$$
Therefore the expected return gained from trading with uninformed traders makes up for the loss incurred by trading with informed traders. To make it a sustainable model, uninformed traders are assumed to trade for exogenous liquidity needs.
Suppose only one trade can happen each day and realization value $V$ is publicly announced tomorrow. The current market belief about $V = \underline{V}$ is $\delta$. To calculate expected value conditioned on market signal (e.g., $p^A = \mathbb{E}(V | s^B)$), we first calculate probability of joint events, i.e., observed market signal and true value
Joint Probability of Value and Market Signal   Joint Probability $V = \overline{V}$ $V = \underline{V}$     $s = s^B$ $(1-\delta)(\mu &#43; \frac{1-\mu}{2})$ $\delta(\frac{1-\mu}{2})$   $s = s^S$ $(1-\delta)(\frac{1-\mu}{2})$ $\delta(\mu &#43; \frac{1-\mu}{2})$    The justification is quite obvious. For example, only uninformed traders will submit a market buy if value goes low. Therefore the joint probability is $\Pr(V=\underline{V})\times\Pr(s = s^B, \theta=\theta^U) = \delta\frac{(1-\mu)}{2}$. And with the information provided from the above table, the bid and ask price can be updated with Bayes Rule:
$$\begin{align*} p^A &amp;amp;= \mathbb{E}(V | s^B) = \overline{V}\Pr(\overline{V}|s^B) &#43; \underline{V}\Pr(\underline{V}|s^B) \cr &amp;amp;= \overline{V}\frac{\Pr(\overline{V},s^B)}{\Pr(s^B)} &#43; \underline{V}\frac{\Pr(\underline{V},s^B)}{\Pr(s^B)} \cr &amp;amp;= \frac{\overline{V}(1-\delta)(1&#43;\mu) &#43; \underline{V}\delta(1-\mu)}{1&#43;\mu(1-2\delta)} \cr \cr p^B &amp;amp;= \overline{V}\Pr(\overline{V}|s^S) &#43; \underline{V}\Pr(\underline{V}|s^S) \cr &amp;amp;= \frac{\overline{V}(1-\delta)(1-\mu) &#43; \underline{V}\delta(1&#43;\mu)}{1-\mu(1-2\delta)} \end{align*}$$
And (initial) spread $p^A - p^B = (\overline{V}-\underline{V})\mu$ is proportional to the risk of information trading if realized value is equally likely a priori (i.e., $\delta=0.5$). We take the derivative of bid and ask w.r.t. the level information risk $\mu$:
$$\begin{align*} \nabla_{\mu} p^A = \frac{2\delta(1-\delta)(\overline{V}-\underline{V})}{(1-\mu-2\delta\mu)^2} &amp;amp;&amp;gt; 0 \cr \cr \nabla_{\mu} p^B = -\frac{2\delta(1-\delta)(\overline{V}-\underline{V})}{(1-\mu&#43;2\delta\mu)^2} &amp;amp;&amp;lt; 0 \cr \end{align*}$$
With higher estimated population of informed trader (or more active informed trading activities), ask price will be set higher and bid price will be set lower. Therefore wider spread (the difference between ask and bid price) will be set to compensate for higher risk.
Multi-period Analysis After the initial trade, the market maker updates her beliefs about the true value according to market signal observed at time $t$ and old belief at $t-1$
$$\begin{align*} \Pr(\underline{V} | s_{1:t-1}, s_t^B) = \delta_t(s_t = s^B; \delta_{t-1}) &amp;amp;= \frac{\delta_{t-1}(1-\mu)}{(1&#43;\mu)-2\delta_{t-1}\mu} \cr \Pr(\underline{V} | s_{1:t-1}, s_t^S) = \delta_t(s_t = s^S; \delta_{t-1}) &amp;amp;= \frac{\delta_{t-1}(1&#43;\mu)}{(1-\mu)&#43;2\delta_{t-1}\mu} \end{align*}$$

The observation is that the probability depends on the differences between types of signals (i.e., market buys and market sells) rather than the ordered sequence of signals. Therefore, the same beliefs about $\underline{V}$ is held as long as total order imbalance is the same (e.g., 2 buys and 3 sells versus 1 sells only). Based on mathematical induction, we can get the following equation for order imbalance:
$$\delta_t(x = N^S_t - N^B_t) = \frac{\delta\left(\frac{1&#43;\mu}{1-\mu}\right)^x}{1-\delta &#43; \delta\left(\frac{1&#43;\mu}{1-\mu}\right)^x}$$
Having updated beliefs about true value, the market maker can then set ask (bid) price accordingly (by anticipating an upcoming market buy (sell) order):
$$\begin{align*} p_{t&#43;1}^A &amp;amp;= \overline{V}\cdot (1-\delta_t(N^S_t - (N^B_t&#43;1))) &#43; \underline{V}\cdot \delta_t(N^S_t - (N^B_t&#43;1)) \cr p_{t&#43;1}^B &amp;amp;= \overline{V}\cdot (1-\delta_t((N^S_t&#43;1) - N^B_t)) &#43; \underline{V}\cdot \delta_t((N^S_t&#43;1) - N^B_t) \end{align*}$$
The figure below shows an example of how price is set by the above equation. A simulated sequence of market signals (buys and sells) is generated and price reflects market maker&#39;s belief about true price based on prior belief and updated signal received:
Plotly.d3.json(&#34;./gm_price.json&#34;, function(err, fig) {Plotly.plot(&#39;.\/gm_price.json&#39;, fig.data, fig.layout, {responsive: true});});Reference [1] Cho, J. W. (2004). State-space representation and estimation of market microstructure models. ÌïúÍµ≠Ï¶ùÍ∂åÌïôÌöåÏßÄ, 33(1), 249-305.
[2] Glosten, L. R., &amp;amp; Milgrom, P. R. (1985). Bid, ask and transaction prices in a specialist market with heterogeneously informed traders. Journal of financial economics, 14(1), 71-100.
[3] Kyle, A. S. (1985). Continuous auctions and insider trading. Econometrica: Journal of the Econometric Society, 1315-1335.
  Since the informed is aware of $V &amp;gt; p_0$ ($V &amp;lt; p_0$), she would submit a positively (negatively) large size of market orders. Because order size from uninformed traders is random, the observed large net orders ($x&#43;u$) suggests a higher involvement of informed trading (i.e., $x$ is also large). &amp;#x21a9;&amp;#xfe0e;
 more noise trading makes it more difficult to discern informed trading activities from the overall net orders. High $\sigma_u$ also implies a liquid market in the sense that large orders can be immediately absorbed by uninformed orders that have little price impact. &amp;#x21a9;&amp;#xfe0e;
  </content>
    </entry><entry>
        <title>Python Unittest File Structure</title>
        <url>https://dennislblog.github.io/2020/04/test_unit/</url>
        <categories>
          
        </categories>
        <tags>
          <tag>python</tag><tag>unittest</tag>
        </tags>
        <content type="html"> The best solution in my opinion is to use the unittest [command line interface]1 which will add the directory to the sys.path so you don&amp;rsquo;t have to (done in the TestLoader class).
For example for a directory structure like this:
new_project ‚îú‚îÄ‚îÄ antigravity.py ‚îî‚îÄ‚îÄ test_antigravity.py  You can just run:
$ cd new_project $ python -m unittest test_antigravity  For a directory structure like yours:
new_project ‚îú‚îÄ‚îÄ antigravity ‚îÇ¬†‚îú‚îÄ‚îÄ __init__.py # make it a package ‚îÇ¬†‚îî‚îÄ‚îÄ antigravity.py ‚îî‚îÄ‚îÄ test ‚îú‚îÄ‚îÄ __init__.py # also make test a package ‚îî‚îÄ‚îÄ test_antigravity.py  And in the test modules inside the test package, you can import the antigravity package and its modules as usual:
# import the package import antigravity # import the antigravity module from antigravity import antigravity # or an object inside the antigravity module from antigravity.antigravity import my_object  Running a single test module:
To run a single test module, in this case test_antigravity.py:
$ cd new_project $ python -m unittest test.test_antigravity  Just reference the test module the same way you import it.
Running a single test case or test method:
Also you can run a single TestCase or a single test method:
$ python -m unittest test.test_antigravity.GravityTestCase $ python -m unittest test.test_antigravity.GravityTestCase.test_method  Running all tests:
You can also use [test discovery]2 which will discover and run all the tests for you, they must be modules or packages named test*.py (can be changed with the -p, --pattern flag):
$ cd new_project $ python -m unittest discover  This will run all the test*.py modules inside the test package.
  https://docs.python.org/2/library/unittest.html#command-line-interface &amp;#x21a9;&amp;#xfe0e;
 https://docs.python.org/2/library/unittest.html#test-discovery &amp;#x21a9;&amp;#xfe0e;
  </content>
    </entry><entry>
        <title>Inverse Reinforcement Learning</title>
        <url>https://dennislblog.github.io/2020/04/inverse-reinforcement-learning/</url>
        <categories>
          
        </categories>
        <tags>
          <tag>thesis</tag><tag>rl</tag><tag>irl</tag>
        </tags>
        <content type="html"> Introduction In this post, I will review most cited approaches in the field of inverse reinforcement learning (and imitation learning) that are pertain to my dissertation. We have two main interests:
 To explain agent&amp;rsquo;s behavior through describing its reward structure and explore the relationship between the informed trading intensities and the reward function (e.g., when informed trading is more likely to occur, the magnitude of price change might be less important than the order imbalance). The learnt policy is most likely going to fail in the new environment. The reward, especially at its simplest form, might be more robust to perturbations of similar but different environment.  Notations    Symbol Meaning     $V(s)$ Value function at state $s$; $V_w(.)$ is a value function characterized by a single parameter $w$.   $V^\pi(s)$ The expected long-term accumulated reward when we start from state $s$ and follow a policy $\pi$ (i.e., $V^\pi (s) = \mathbb{E}_{a\sim \pi} [G_t \vert S_t = s]$).   $P_{a^\star}$ Transition probability of getting to the next state $s&#39;$ from the current state $s$ with the action $a^\star = \arg\max_{a} \sum_{s&amp;rsquo;} P_{s,a}^{s&amp;rsquo;}V^\pi(s&amp;rsquo;)$    Linear Inverse Reinforcement Learning The goal is to recover a reward function under which the expert&amp;rsquo;s policy is optimal. For large state space, reward is approximated from a set of relevant features.
Assumptions  the transition probability $P_{s,a}^{s&amp;rsquo;}$ is assumed to be known or can be accurately estimated via Monte Carlo. the expert&amp;rsquo;s policy is optimal  IRL in Finite State Space from the Bellman equation, we have $$\mathbf{V^\pi} = \mathbf{R} &#43; \gamma \mathbf{P}_{a^*} \mathbf{V^\pi} \Rightarrow \mathbf{V^\pi} = (\mathbf{I} - \gamma \mathbf{P}_{a^*})^{-1} \mathbf{R}$$
Since the expert&amp;rsquo;s policy always achieves the highest value at each state, we have $$\begin{align*} \forall a \in A \setminus a^{*},\mathbf{R} &#43; \gamma \mathbf{P}_{a^*} \mathbf{V^\pi} &amp;amp;\succeq \mathbf{R} &#43; \gamma \mathbf{P}_{a} \mathbf{V^\pi}\newline (\mathbf{P}_{a^*} - \mathbf{P}_{a}) (\mathbf{I} - \gamma \mathbf{P}_{a^*})^{-1} \mathbf{R} &amp;amp;\succeq 0 \end{align*}$$ The above serves as the main constraint for solving the inverse MDP. Similar to finding the hyperplane that maximizes the margin between the two classes, we hope to find a reward function that maximizes the gap of expected value between expert&amp;rsquo;s policy and suboptimal policies. To avoid the situation where the reward received at a few states is arbitrarily high because of noise signals, they&amp;rsquo;ve added a $l_1$ penalty on the reward to prevent overfitting:
$$\begin{align*} \text{maximize}&amp;amp; \sum_{s\in S} \ \left[\text{min}_{a \in A \setminus a^*} (\mathbf{P}_{a^*,s} - \mathbf{P}_{a,s}) (\mathbf{I} - \gamma \mathbf{P}_{a^*})^{-1} \mathbf{R}\right] - \lambda ||\mathbf{R}||_1 \newline \text{s.t. }&amp;amp; (\mathbf{P}_{a^*} - \mathbf{P}_{a}) (\mathbf{I} - \gamma \mathbf{P}_{a^*})^{-1} \mathbf{R} \succeq 0, \forall a \in A \setminus a^{*} \end{align*}$$
IRL in Infinite State Space When state and action spaces are continuous, constraints are infinite and problem becomes intractable. Just like we use Q-function to approximate Q-value in the reinforcement learning continuous setting, we write reward function as a linear combination of several basis function. Each basis function can be thought of as a feature extractor out of the original observational state. And the total reward (i.e., $V^\pi(s_0)$) is a weighted sum of total rewards of these basis function.
$$ \begin{align*} V^{\pi}(s_0) &amp;amp;= \mathbb{E}\left[R(s_0) &#43; \gamma R(s_1) &#43; &amp;hellip; | \pi\right]\cr &amp;amp;= \mathbb{E}[ w_1\phi_1(s_0)&#43;w_2\phi_2(s_0) &#43; &amp;hellip; &#43; w_d\phi_d(s_0) \cr &amp;amp;\quad &#43; \gamma[w_1\phi_1(s_1)&#43;w_2\phi_2(s_1) &#43; &amp;hellip; &#43; w_d\phi_d(s_1) \cr &amp;amp; \qquad\qquad\qquad \vdots \cr &amp;amp; =\mathbb{E}[w_1\cdot[\phi_1(s_0) &#43; \gamma\phi_1(s_1)&#43; \cdots]\cr &amp;amp;\quad&#43;w_2\cdot[\phi_2(s_0) &#43; \gamma\phi_1(s_2)&#43; \cdots]\cr &amp;amp;\qquad\qquad\qquad \vdots \cr &amp;amp;\quad&#43;w_d\cdot[\phi_d(s_0) &#43; \gamma\phi_d(s_1)&#43; \cdots | \pi] \cr &amp;amp;=w_1\mu_1 &#43; w_2\mu_2 &#43; \cdots &#43; w_d\mu_d \end{align*} $$
 So if immediate rewardis truly a linear combination of several state feature produced by basis functionÔºåwe can see each as a reward of independent subtask (even if their rewards are related). Then to maximize total reward, we can instead focus on maximizing reward of each subtasks. The problem is to maximize value gap between the expert&amp;rsquo;s policy and any non-expert&amp;rsquo;s policy with the constructed reward function:
 $$ \begin{align*} \text{maximize} \sum_{s\in S} \text{min}_{a\in A \setminus a^*} &amp;amp; \eta\left[\mathbf{E}_{s&amp;rsquo;\sim P_{sa^*}} [V^\pi(s&amp;rsquo;)] - \mathbf{E}_{s&amp;rsquo;\sim P_{sa}} [V^\pi(s&amp;rsquo;)]\right] \cr \text{s.t. } &amp;amp;|a_i| \leq 1, i = 1,..,d \end{align*} $$
Where $\eta(x) = 1 \text{ if } x \geq 0$ otherwise $\eta(x) = 2$ because linear approximator of reward might be incorrect. To avoid the situation where the expected long-term accumulated reward of non-expert&amp;rsquo;s policy developed via the incorrect reward is higher than that of expert&amp;rsquo;s policy, the algorithm adds double the size of penalty on its value gap.
Evaluation The percentage of states in which the constructed reward&amp;rsquo;s optimal policy disagrees with the true optimal policy.
Follow up Levine, Popovic and Koltun&amp;rsquo;s work on dynamic selection of relevant features from a large collection of component features, many of whom may be irrelevant for the expert&amp;rsquo;s policy.
Apprenticeship Learning Reference [1] Ng, A. Y., &amp;amp; Russell, S. J. (2000, June). Algorithms for inverse reinforcement learning. In Icml (Vol. 1, p. 2)
[2] Levine, S., Popovic, Z., &amp;amp; Koltun, V. (2010). Feature construction for inverse reinforcement learning. In Advances in Neural Information Processing Systems (pp. 1342-1350).
</content>
    </entry><entry>
        <title>Cupper Shortcodes</title>
        <url>https://dennislblog.github.io/2019/02/cupper-shortcodes/</url>
        <categories>
          
        </categories>
        <tags>
          <tag>hugo</tag><tag>shortcodes</tag>
        </tags>
        <content type="html"> blockquote {{&amp;lt; blockquote author=&amp;quot;Carl Jung&amp;quot; &amp;gt;}} Even a happy life cannot be without a measure of darkness, and the word happy would lose its meaning if it were not balanced by sadness. It is far better to take things as they come along with patience and equanimity. {{&amp;lt; /blockquote &amp;gt;}} Even a happy life cannot be without a measure of darkness, and the word happy would lose its meaning if it were not balanced by sadness. It is far better to take things as they come along with patience and equanimity.&amp;mdash; Carl Jung notice {{&amp;lt; notice &amp;quot;The Title of This Notice&amp;quot; &amp;gt;}} This is a note! It&#39;s something the reader may like to know about but is supplementary to the main content. Use notes when something may be interesting but not critical. {{&amp;lt; /notice &amp;gt;}} .notice{padding:18px;line-height:24px;border-radius:4px;color:#444;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:0.125em;position:relative}The Title of This NoticeThis is a note! It&amp;rsquo;s something the reader may like to know about but is supplementary to the main content. Use notes when something may be interesting but not critical.
 expandable {{&amp;lt; expandable label=&amp;quot;A section of dummy text&amp;quot; level=&amp;quot;2&amp;quot; &amp;gt;}} Here is some markdown including [a link](https://twitter.com/heydonworks). Donec erat est, feugiat a est sed, aliquet pharetra ipsum. Vivamus in arcu leo. Praesent feugiat, purus a molestie ultrices, libero massa iaculis ante, sit amet accumsan leo eros vel ligula. {{&amp;lt; /expandable &amp;gt;}} A section of dummy textHere is some markdown including a link. Donec erat est, feugiat a est sed, aliquet pharetra ipsum. Vivamus in arcu leo. Praesent feugiat, purus a molestie ultrices, libero massa iaculis ante, sit amet accumsan leo eros vel ligula.A section of dummy textHere is some markdown including a link. Donec erat est, feugiat a est sed, aliquet pharetra ipsum. Vivamus in arcu leo. Praesent feugiat, purus a molestie ultricesA section of dummy textHere is some markdown including a link. Donec erat est, feugiat a est sed, aliquet pharetra ipsum. Vivamus in arcu leo. Praesent feugiat, purus a molestie ultrices, libero massa iaculis ante, sitgallery {{&amp;lt; photoswipe &amp;gt;}} //one loading each page {{&amp;lt; gallery caption-effect=&amp;quot;fade&amp;quot; caption-position=&amp;quot;bottom&amp;quot; &amp;gt;}} {{&amp;lt; figure src=&amp;quot;./sun.jpg&amp;quot; caption=&amp;quot;this is a $\odot$&amp;quot; &amp;gt;}} {{&amp;lt; figure src=&amp;quot;./1.jpg&amp;quot; caption=&amp;quot;a beautiful scenery&amp;quot; &amp;gt;}} {{&amp;lt; /gallery &amp;gt;}}    this is a $\odot$
      a beautiful scenery
   
figure ![The Sun is the star at the center of the Solar System. Its width is 70% of origin $üòÄ$ |||70](sun.jpg) 
Plot {{&amp;lt; load-ployly &amp;gt;}} //one loading each page {{&amp;lt; plotly json=&amp;quot;./myplot.json&amp;quot; height=&amp;quot;500px&amp;quot; &amp;gt;}} Plotly.d3.json(&#34;./myplot.json&#34;, function(err, fig) {Plotly.plot(&#39;.\/myplot.json&#39;, fig.data, fig.layout, {responsive: true});});Code 1 &amp;#34;&amp;#34;&amp;#34;Prioritized replay Buffer with N-step collection of rewards based on TD error&amp;#34;&amp;#34;&amp;#34; 2class PrioritizedReplayBuffer(ReplayBuffer): 3 &amp;#34;&amp;#34;&amp;#34; transition = (obs, act, rew, next_obs, done) &amp;#34;&amp;#34;&amp;#34; 4 def __init__(self, obs_dim, size, batch_size, n_step, gamma): 5 self.n_step_buffer = deque(maxlen=n_step) #make a comment 6 self.sum_tree = SumSegmentTree(tree_capacity) Dynamic Tabs {{&amp;lt; tabs tabTotal=&amp;quot;3&amp;quot; tabID=&amp;quot;1&amp;quot; tabName1=&amp;quot;Tab 1&amp;quot; tabName2=&amp;quot;Tab 2&amp;quot; tabName3=&amp;quot;Tab 3&amp;quot; &amp;gt;}} {{&amp;lt; tab tabNum=&amp;quot;1&amp;quot; &amp;gt;}} **Tab 1 Content** {{&amp;lt; /tab &amp;gt;}} {{&amp;lt; tab tabNum=&amp;quot;2&amp;quot; &amp;gt;}} **Tab 2 Content** {{&amp;lt; /tab &amp;gt;}} {{&amp;lt; tab tabNum=&amp;quot;3&amp;quot; &amp;gt;}} **Tab 3 Content** {{&amp;lt; /tab &amp;gt;}} {{&amp;lt; /tabs &amp;gt;}}  Tab 1 Tab 2 Tab 3   Tab 1 Content  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum
1var test = &amp;#34;not formatted&amp;#34; Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum
 Tab 3 Content    Acknowledgements  @liwenyip for Easy Gallery @ig248 for Plotly Figures @rvanhorn for Dynamic Tabs @martignoni for Notice Block  </content>
    </entry>
</search>